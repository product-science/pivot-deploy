[
  {
    "id": "mlnode1",
    "host": "inference",
    "inference_port": 5000,
    "poc_port": 8080,
    "max_concurrent": 500,
    "models": {
      "Qwen/Qwen2.5-7B-Instruct": {
        "args": [
          "--quantization",
          "fp8"
        ]
      }
    },
    "hardware": [
      {
        "type": "3090",
        "count": 1
      }
    ]
  }
]