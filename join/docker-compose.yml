services:
  tmkms:
    image: ghcr.io/product-science/tmkms-softsign-with-keygen:0.1.4
    container_name: tmkms
    restart: unless-stopped
    environment:
      - VALIDATOR_LISTEN_ADDRESS=tcp://node:${TMKMS_PORT:-26658}
    volumes:
      - tmkms_data:/root/.tmkms

  node:
    container_name: node
    image: ghcr.io/product-science/inferenced:0.1.4
    command: ["sh", "./init-docker.sh"]
    volumes:
      - .inference:/root/.inference
    environment:
      - SEED_NODE_RPC_URL=${SEED_NODE_RPC_URL}
      - SEED_NODE_P2P_URL=${SEED_NODE_P2P_URL}
      - SNAPSHOT_INTERVAL=1000
      - SNAPSHOT_KEEP_RECENT=5
      - TRUSTED_BLOCK_PERIOD=${TRUSTED_BLOCK_PERIOD:-2000}
      - KEY_NAME=${KEY_NAME}
      - P2P_EXTERNAL_ADDRESS=${P2P_EXTERNAL_ADDRESS}
      - CONFIG_p2p__allow_duplicate_ip=true
      - CONFIG_p2p__handshake_timeout=30s
      - CONFIG_p2p__dial_timeout=30s
      - TMKMS_PORT=${TMKMS_PORT:-26658}
      - SYNC_WITH_SNAPSHOTS=true
      - RPC_SERVER_URL_1=${RPC_SERVER_URL_1}
      - RPC_SERVER_URL_2=${RPC_SERVER_URL_2}
    ports:
      - "5000:26656" #p2p
      - "26657:26657" #rpc
    expose:
      - "${TMKMS_PORT:-26658}"
    depends_on:
      - tmkms
    restart: always

  api:
    container_name: api
    image: ghcr.io/product-science/api:0.1.4
    volumes:
      - .inference:/root/.inference
      - ${NODE_CONFIG:-./node-config.json}:/root/node_config.json
    depends_on:
      - node
    environment:
      - KEY_NAME=${KEY_NAME}
      - DAPI_API__POC_CALLBACK_URL=${DAPI_API__POC_CALLBACK_URL}
      - DAPI_API__PUBLIC_URL=${PUBLIC_URL}
      - DAPI_CHAIN_NODE__SEED_API_URL=${SEED_API_URL}
      - DAPI_CHAIN_NODE__URL=${DAPI_CHAIN_NODE__URL}
      - DAPI_CHAIN_NODE__P2P_URL=${DAPI_CHAIN_NODE__P2P_URL}
      - NODE_CONFIG_PATH=/root/node_config.json
      - DAPI_API__PUBLIC_SERVER_PORT=9000
      - DAPI_API__ML_SERVER_PORT=9100
      - DAPI_API__ADMIN_SERVER_PORT=9200
    ports:
      - "${API_PORT}:9000"
      - "9100:9100"
      - "9200:9200"
    restart: always

  inference:
    image: ghcr.io/product-science/mlnode:3.0.4-alpha2
    volumes:
      - ${HF_HOME:-${HOME}/cache}:/root/.cache
    environment:
      - HF_HOME=/root/.cache
      - VLLM_ATTENTION_BACKEND=FLASHINFER
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    ipc: host
    command: >
      uvicorn api.app:app
      --host=0.0.0.0
      --port=8080
    restart: always

volumes:
  tmkms_data:
