services:
  node:
    container_name: node
    image: gcr.io/decentralized-ai/inferenced
    command: ["sh", "./init-docker-genesis.sh"]
    volumes:
      - .inference:/root/.inference
    environment:
      - KEY_NAME=${KEY_NAME}
    ports:
      - "26656:26656" #p2p
      - "26657:26657" #rpc
  api:
    container_name: api
    image: gcr.io/decentralized-ai/api
    depends_on:
      - node
    environment:
      - KEY_NAME=${KEY_NAME}
      - POC_CALLBACK_URL=${POC_CALLBACK_URL}
      - PORT=${PORT}
    ports:
      - "${PORT}:8080"
    volumes:
      - .inference:/root/.inference

  inference-node:
    image: gcr.io/decentralized-ai/mlnode:debug
    ports:
      - "8000:8080"
      - "5000:5000"
    volumes:
      - ./resources:/app/resources:r
      - ./cache:/root/.cache
    environment:
      - MODEL_PARAMS_PATH=/app/resources/params.json
      - HF_HOME=/root/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command: >
      uvicorn pow.app:app
      --host=0.0.0.0
      --port=8080

volumes:
  inference-data:
