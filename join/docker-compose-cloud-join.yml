services:
  node:
    container_name: node
    image: 172.18.114.101:5556/decentralized-ai/inferenced:0.0.1-alpha3
    command: ["sh", "./init-docker.sh"]
    volumes:
      - .inference:/root/.inference
    environment:
      - SEED_NODE_RPC_URL=${SEED_NODE_RPC_URL}
      - SEED_NODE_P2P_URL=${SEED_NODE_P2P_URL}
      - SYNC_WITH_SNAPSHOTS=${SYNC_WITH_SNAPSHOTS} # sync using snapshots?
      - RPC_SERVER_URL_2=${RPC_SERVER_URL_2}       # rpc-servers to get snapshots
      - RPC_SERVER_URL_1=${RPC_SERVER_URL_1}
      - TRUSTED_BLOCK_PERIOD=${TRUSTED_BLOCK_PERIOD:-2000} # num of blocks to return back from latest block to get the earliest trusted snapshot
      - KEY_NAME=${KEY_NAME}
    ports:
      - "26656:26656" #p2p
      - "26657:26657" #rpc
  api:
    container_name: api
    image: 172.18.114.101:5556/decentralized-ai/api:0.0.1-alpha3
    volumes:
      - .inference:/root/.inference
      - ./node-config.json:/root/node_config.json
    depends_on:
      - node
    environment:
      - KEY_NAME=${KEY_NAME}
      - DAPI_API__POC_CALLBACK_URL=${DAPI_API__POC_CALLBACK_URL}
      - DAPI_API__PUBLIC_URL=${PUBLIC_URL}
      - DAPI_CHAIN_NODE__SEED_API_URL=${SEED_API_URL}
      - NODE_CONFIG_PATH=/root/node_config.json
    ports:
      - "${PORT:-8000}:8080"
    restart: always

  inference-node:
    image: 172.18.114.101:5556/decentralized-ai/mlnode:3.0.1-alpha1
    volumes:
      - ${HOME}/cache:/root/.cache
    environment:
      - HF_HOME=/root/.cache
      - HF_HUB_ENABLE_HF_TRANSFER=true
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    command: >
      uvicorn api.app:app
      --host=0.0.0.0
      --port=8080
    restart: always