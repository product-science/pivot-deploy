services:
  inference:
    image: gcr.io/decentralized-ai/mlnode:3.0.3-alpha1
    command: >
      uvicorn api.app:app
      --host=0.0.0.0
      --port=8080
    ports:
      - "8080:8080"
    environment:
      - HF_HOME=/root/.cache
    volumes:
      - type: bind
        source: /srv/cache
        target: /root/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
