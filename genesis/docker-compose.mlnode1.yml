services:
  inference:
    image: ghcr.io/product-science/mlnode:3.0.4-alpha2
    restart: always
    command: >
      uvicorn api.app:app
      --host=0.0.0.0
      --port=8080
    environment:
      - HF_HOME=/root/.cache
      - VLLM_ATTENTION_BACKEND=FLASHINFER
    volumes:
      - /srv/dai/cache:/root/.cache
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

networks:
  genesis-network:
    driver: bridge
    external: true