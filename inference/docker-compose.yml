services:
  inference:
    image: ghcr.io/product-science/mlnode:3.0.7
    volumes:
      - ${HF_HOME:-${HOME}/cache}:/root/.cache
    environment:
      - HF_HOME=/root/.cache
      - VLLM_ATTENTION_BACKEND=FLASHINFER
    ports:
      - "${PORT:-8000}:8080"
      - "5000:5000"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    ipc: host
    command: >
      uvicorn api.app:app
      --host=0.0.0.0
      --port=8080
    restart: always
